{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb5OC0PIgpuM",
        "outputId": "7b21e392-418d-4f62-86d7-5bdf04b2fe41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install igraph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keOZLfAihHxz",
        "outputId": "ec36edf0-198f-4374-8e51-1bd422edeff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: igraph in /usr/local/lib/python3.7/dist-packages (0.9.9)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from igraph) (1.6.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os \n",
        "import random\n",
        "import math\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt \n",
        "from scipy.stats import ttest_ind\n",
        "import more_itertools\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import tqdm\n",
        "from datetime import datetime\n",
        "from sklearn.cluster import KMeans\n",
        "#import igraph as ig\n",
        "import json\n",
        "import scipy.io\n",
        "import statistics\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "X0W4uv8hhNR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path pour Mathusan\n",
        "PATH_DATA = '/content/drive/Othercomputers/My Laptop (1)/Systeme de Recommendation/TP/TP2/Data'\n",
        "#PATH_DATA = '/content/drive/Othercomputers/My Laptop/TP2/'\n",
        "\n",
        "#PATH_DATA = \"/content/drive/MyDrive/Colab Notebooks/POLTECHNIQUE/Hiver2022/System de recommendation/TP2\"\n",
        "#PATH_DATA='/content/drive/MyDrive/POLYTECHNIQUE/Hiver2022/System de recommendation/TP2'"
      ],
      "metadata": {
        "id": "aQ2tr5xghxmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # items \n",
        "# test_data = pd.read_csv(os.path.join(PATH_DATA, '12-articles.csv'))\n",
        "# # # users\n",
        "# with open(os.path.join(PATH_DATA, 'dblpv13.json')) as file:\n",
        "#   train_data=json.load(file)\n",
        "# # # votes\n",
        "# # votes = json.load(os.path.join(PATH_DATA, 'votes.csv'), sep='|')"
      ],
      "metadata": {
        "id": "178t4ydmiC_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read adjacency matrix file\n",
        "adjacency_matrix = scipy.io.mmread(os.path.join(PATH_DATA, 'tp-matrix.dgt'))\n",
        "adjacency_matrix=adjacency_matrix.tocsr()\n",
        "#treating entries more than 1\n",
        "adjacency_matrix[adjacency_matrix>1]=1\n",
        "#reading articles names file\n",
        "node_names=pd.read_csv(os.path.join(PATH_DATA, 'tp-matrix-names.csv'), sep=\"\\s+\")\n",
        "node_names.rename(columns={'x':'titre'},inplace=True)\n",
        "#reading test file\n",
        "test_nodes=pd.read_csv(os.path.join(PATH_DATA, '12-articles.csv'))\n",
        "# node_names=node_names.reset_index()"
      ],
      "metadata": {
        "id": "LH7KeEHY3kTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q.1"
      ],
      "metadata": {
        "id": "e8Oy4eMG3zMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate pageRank the maximum iteration is 1000 but the if the difference between current step and previous step is less than epsilon the function will stop\n",
        "def calcul_general_page_rank(adjacency_matrix,d=0.85, max_iter=1000, epsilon=1e-5):\n",
        "  #initialize page rank\n",
        "  r_prev=np.array([[1]]*adjacency_matrix.shape[0])\n",
        "  for i in range(max_iter):\n",
        "    #to avoid division by 0, the denominator  increases by 1\n",
        "    r_cur=np.array((1-d)/(adjacency_matrix.shape[0])+d*(adjacency_matrix.T*(r_prev/(adjacency_matrix.sum(axis=1)+1))))\n",
        "    if np.mean(np.abs(r_cur-r_prev))<1e-5:\n",
        "      #to know the number of iteration to achive convergence we print i\n",
        "      #print(f'number of iteration was: {i}')\n",
        "      break\n",
        "    else:\n",
        "      r_prev=r_cur\n",
        "\n",
        "  return r_cur\n"
      ],
      "metadata": {
        "id": "GRWRfo1tA8iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r=calcul_general_page_rank(adjacency_matrix)\n",
        "#using transpose and the first element of r give a row vector of (50497,)\n",
        "r.T[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SThbfYIQBR5I",
        "outputId": "79aaed45-1c9f-49da-b0a3-6cbb9c1aac2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.57674773e-06, 5.36145139e-04, 2.39036472e-05, ...,\n",
              "       2.97047349e-06, 3.47545399e-06, 2.97047349e-06])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_mrr(test_nodes):\n",
        "  #list of mean of mrr of test articles\n",
        "  mrr_test=[]\n",
        "  for id in test_nodes['id']:\n",
        "    #relevant articles based on adjacency matrix rows\n",
        "    pertinent_articles_index=adjacency_matrix[node_names[node_names[\"titre\"]==id].index-1].nonzero()[1]\n",
        "\n",
        "    # pagerank(r)\n",
        "    r=calcul_general_page_rank(adjacency_matrix)\n",
        "    #sorting index of relevant article using page rank in ascending order and getting top 10\n",
        "    top_articles=np.argsort(r.T[0][pertinent_articles_index])[::-1]\n",
        "\n",
        "    #getting title of top 10 article it is commented\n",
        "\n",
        "\n",
        "    #calculate MRR\n",
        "\n",
        "    #sorting index pagerank list\n",
        "    r_index_sorted=np.argsort(r.T[0])[::-1]\n",
        "    #list of mrr for recommendations of an article \n",
        "    mrr_list=[]\n",
        "\n",
        "    for article in pertinent_articles_index[list(top_articles)]:\n",
        "      #find the rank of each recommended article\n",
        "      rank_relevant_article=np.where(r_index_sorted==article)\n",
        "      #appending mrr of each artcle to the list, add 1 to index to consider the difference between rank and index\n",
        "      mrr_list.append(1/(rank_relevant_article[0][0]+1))\n",
        "    \n",
        "    #mean of mrr of recommended articles for an article\n",
        "\n",
        "    mrr_mean=statistics.mean(mrr_list)\n",
        "    #appending the mean of mrr for each test artcle\n",
        "    mrr_test.append(mrr_mean)\n",
        "  \n",
        "    print(f' MRR for article id:{id} is: {mrr_mean}')\n",
        "  meant_total=statistics.mean(mrr_test)\n",
        "  print(f'\\n ***Mean MRR for 12 test article is:*** {meant_total}')\n",
        "  #return mrr_test, meant_total\n",
        "\n",
        "calc_mrr(test_nodes)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2BnK9tFQMPZ",
        "outputId": "817e46d1-c3a2-4a51-f3a1-93cd8dc1ec96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MRR for article id:53e9aa4fb7602d97033bee00 is: 0.00035932416665122093\n",
            " MRR for article id:53e9b098b7602d9703b03c4e is: 0.00042097762611217903\n",
            " MRR for article id:53e9b708b7602d97042a150f is: 6.77031438904695e-05\n",
            " MRR for article id:53e9ba6ab7602d970468b7d5 is: 0.0003019991384712623\n",
            " MRR for article id:53e9ad6cb7602d9703755d9b is: 0.01233074966658952\n",
            " MRR for article id:558b5658e4b037c0875c5887 is: 0.0009192031308223445\n",
            " MRR for article id:558b416a84ae84d265c25bff is: 0.004041173835406845\n",
            " MRR for article id:53e99984b7602d97021c6204 is: 0.0018726131581843083\n",
            " MRR for article id:53e9b917b7602d97044fd88f is: 0.001547271902455532\n",
            " MRR for article id:53e9b360b7602d9703e3f04a is: 0.000854077693163559\n",
            " MRR for article id:53e9b879b7602d9704446291 is: 0.0006752420777899296\n",
            " MRR for article id:53e99bc0b7602d970246a745 is: 0.00013024084239606583\n",
            "\n",
            " ***Mean MRR for 12 test article is:*** 0.00196004803182777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis  \n",
        "In this part we calculated general pagerank. It means that we give the same probability of random walk (teleportation) to all articles in the set. In the nex part we will try to be more subject oriented and limit teleportation to articles that are relevant and similar to the target article."
      ],
      "metadata": {
        "id": "X8FzF6GT09yS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "NGvl4X4-C5v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FINAL VERSION OF THE FINAL VERSION OF THE FINAL VERSION exposant final version !!!"
      ],
      "metadata": {
        "id": "r3h2vHdRXypR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new version\n",
        "#calculating the resulting sparse vector from the summation of different levels of relation between the ajdacency matrix\n",
        "def calc_order(adjacency_matrix, ind):\n",
        "  ordre_1=adjacency_matrix[ind]\n",
        "  ordre_n1=adjacency_matrix.T[ind]\n",
        "  ordre_11=ordre_1.dot(adjacency_matrix)\n",
        "  ordre_1n1=ordre_1.dot(adjacency_matrix.T)\n",
        "  ordre_n11=ordre_n1.dot(adjacency_matrix)\n",
        "  ordre_1n11=ordre_1.dot(adjacency_matrix.T.dot(adjacency_matrix))\n",
        "  ordre_n111=ordre_n1.dot(adjacency_matrix.dot(adjacency_matrix))\n",
        "  order=ordre_1+ordre_n1+ordre_11+ordre_1n1+ordre_1n11+ordre_1n11+ordre_n111\n",
        "  # order=adjacency_matrix+adjacency_matrix.T+adjacency_matrix.multiply(adjacency_matrix)+adjacency_matrix.multiply(adjacency_matrix.T)+adjacency_matrix.T.multiply(adjacency_matrix)+adjacency_matrix.multiply(adjacency_matrix.T)*adjacency_matrix.T+adjacency_matrix.T*adjacency_matrix*adjacency_matrix\n",
        "  #making sure the resulting vector is binary\n",
        "  order[order>1]=1\n",
        "  return order"
      ],
      "metadata": {
        "id": "K-E-0E3aZCo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new version\n",
        "def calcul_thematique_rank2(adjacency_matrix,thematic_matrix, d=0.85,  max_iter=1000, epsilon=1e-5):\n",
        "  #initialize page rank\n",
        "  dict={}\n",
        "  # for i in tqdm(range(adjacency_matrix.shape[0])):\n",
        "  r_prev=np.array([[0]]*adjacency_matrix.shape[0])\n",
        "  #thematic_matrix=calc_order(adjacency_matrix) #calculate thematic matrix\n",
        "  thematic_articles_index=thematic_matrix.nonzero()[1]\n",
        "  #initialize the pagerank to the values of the thematic vector\n",
        "  r_prev[thematic_articles_index]=1\n",
        "  teleport=r_prev.copy()\n",
        "  #iterate the pagerank so that the difference between the previous and the current pagerank is quite the same\n",
        "  for i in range(max_iter):\n",
        "    #calculating the pagerank \n",
        "    r_cur=np.array(((1-d)/len(teleport[teleport==1])*teleport)+d*(adjacency_matrix.T*(r_prev/(adjacency_matrix.sum(axis=1)+1)))) #(m_l_o.T*(r_prev/(m_l_o.sum(axis=1)+1))))\n",
        "    if np.mean(np.abs(r_cur-r_prev))<1e-5:\n",
        "      #to know the number of iteration to achive convergence we print i\n",
        "\n",
        "      break\n",
        "    else:\n",
        "      #updating the current and previous pagerank\n",
        "      r_prev=r_cur\n",
        "\n",
        "  return r_cur\n",
        "#id=test_nodes['id'][9]#3000 (,3262,3276)\n",
        "#articles=adjacency_matrix[node_names[node_names[\"titre\"]==id].index-1]\n",
        "#articles_sparse_original=articles.toarray()[0]\n",
        "#calcul_general_page_rank2(adjacency_matrix,articles_sparse_original)"
      ],
      "metadata": {
        "id": "mb5J-1Mva_SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main function to calculate the mrr through the use of the methods above\n",
        "\n",
        "def mrr_q2(test_nodes,adjacency_matrix):    \n",
        "    results=[]\n",
        "    for id in test_nodes['id']:#3000 (,3262,3276)\n",
        "        #get the index of the current test id in the adjacency matrix\n",
        "        ind=node_names[node_names[\"titre\"]==id].index[0]-1\n",
        "        #print the title of the test if \n",
        "        print('**',test_nodes.loc[test_nodes['id']==id,'titre'].iloc[0],'**')\n",
        "        #get the line for the given title\n",
        "        articles_ref=adjacency_matrix[node_names[node_names[\"titre\"]==id].index-1]\n",
        "        #calculate the resulting  (transformed matrix)\n",
        "        article_them=calc_order(adjacency_matrix,ind)\n",
        "\n",
        "        #transfer the vector of the given index from the original matrix\n",
        "        articles_sparse_original_ref=articles_ref.toarray()[0]\n",
        "        #transfer the vector of the given index from the transformed matrix\n",
        "        articles_sparse_original_them=article_them.toarray()[0]\n",
        "\n",
        "        #calculate the ranking for the nul values by calculating the median of their ranks (as instructed by the statement)\n",
        "        rang_nulle=sum(list(range(np.count_nonzero(articles_sparse_original_them),len(articles_sparse_original_them))))/(len(articles_sparse_original_them)-np.count_nonzero(articles_sparse_original_them))\n",
        "        rank_lov=[]\n",
        "        #iterate over the non zero articles of the vector\n",
        "        for a in list(np.nonzero(articles_sparse_original_ref)[0]):\n",
        "            #turn the value of the non zero (a) to zero\n",
        "            article_sparse=articles_sparse_original_ref.copy()\n",
        "            article_sparse[a]=0\n",
        "            adjacency_thematique=adjacency_matrix.copy()\n",
        "            adjacency_thematique[ind,a]=0\n",
        "            #perform the thematic adjacency over the modified a->0 vector\n",
        "            thematique=calc_order(adjacency_thematique,ind)\n",
        "            \n",
        "            #calculate the rank from the resulting vector of the thematic + a->0 matrix\n",
        "            rang_sort=calcul_thematique_rank2(adjacency_matrix,thematique)\n",
        "            #sort the ranks\n",
        "            rang_sort=np.argsort(rang_sort.T[0])[::-1]\n",
        "            #initialize a mrr list\n",
        "            mrr_list=[]\n",
        "            #fill the rank elif the thematic value for the coordinates are still 0 or not\n",
        "            if thematique[0,a]==0:\n",
        "                mrr_list.append(1/rang_nulle)\n",
        "            else:\n",
        "\n",
        "                rang=np.where(rang_sort==a)[0][0]+1\n",
        "                mrr_list.append(1/rang)\n",
        "            #fill the values for the other coordinates of the vector which is not equal to a\n",
        "            for b in list(np.nonzero(articles_sparse_original_ref)[0]):\n",
        "            #for b in list(np.nonzero(article_sparse)):\n",
        "                if b!=a:\n",
        "                    rang_rest=np.where(rang_sort==b)[0][0]+1\n",
        "                    mrr_list.append(1/rang_rest)\n",
        "            #fill the rank_lov array with the mean of the mrr\n",
        "            rank_lov.append(statistics.mean(mrr_list))\n",
        "        print(\"For which the MRR is :\")\n",
        "        results.append(statistics.mean(rank_lov))\n",
        "        print(statistics.mean(rank_lov))\n",
        "    print(f'\\n ***Mean MRR for 12 test article is:*** {statistics.mean(results)}')\n",
        "        \n",
        "\n",
        "mrr_q2(test_nodes,adjacency_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcbMGgiWbp1t",
        "outputId": "70982756-9203-485e-a84f-2504c362d274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Joint Energy Management and Resource Allocation in Rechargeable Sensor Networks **\n",
            "For which the MRR is :\n",
            "0.01089403395719747\n",
            "** Qualitative organization of collections of shapes via quartet analysis **\n",
            "For which the MRR is :\n",
            "0.005754574109713856\n",
            "** Using the fuzzy multi-criteria decision making approach for measuring the possibility of successful knowledge management **\n",
            "For which the MRR is :\n",
            "0.10151231295384355\n",
            "** Multi-Scale Adaptive Sampling with Mobile Agents for Mapping of Forest Fires **\n",
            "For which the MRR is :\n",
            "0.30857986861758036\n",
            "** Randomized locality sensitive vocabularies for bag-of-features model **\n",
            "For which the MRR is :\n",
            "0.06807897673591592\n",
            "** Cache-Leakage Resilient OS Isolation in an Idealized Model of Virtualization **\n",
            "For which the MRR is :\n",
            "0.016069834081623147\n",
            "** Discrete tracking of parametrized curves **\n",
            "For which the MRR is :\n",
            "0.08919002869064693\n",
            "** Spatial template extraction for image retrieval by region matching. **\n",
            "For which the MRR is :\n",
            "0.040278690888093376\n",
            "** Distance sets for shape filters and shape recognition. **\n",
            "For which the MRR is :\n",
            "0.004667274197517139\n",
            "** Automating cross-layer diagnosis of enterprise wireless networks **\n",
            "For which the MRR is :\n",
            "0.08682201984838783\n",
            "** Content delivery and caching from a network provider's perspective **\n",
            "For which the MRR is :\n",
            "0.02772634479278293\n",
            "** A review of recent advances in learner and skill modeling in intelligent learning environments **\n",
            "For which the MRR is :\n",
            "0.00674069593475229\n",
            "\n",
            " ***Mean MRR for 12 test article is:*** 0.0638595545673379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis \n",
        "Performing a PageRank on all the articles but keeping only the relevant articles for the calculation of the 12 components of the MRR, we get a much better MRR (0.0638595545673379) than in Question 1. In this part we increase the probability of random walk to articles that only are present in the Thematic graph. Therefore their PR increases comparing to other articles and they will have higher rank and MRR will increases. Please note that the probability of random walk to non-relevant articles are 0 here.\n",
        "\n"
      ],
      "metadata": {
        "id": "4X83rDxGCdwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qestion 3"
      ],
      "metadata": {
        "id": "PYGPVPxbR1HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def article_recom_similarity(adjacency_matrix,node_names,test_nodes,Thematic=False):\n",
        "  #initialize a dictionnary of similarity and a mrr array\n",
        "  dict_similar={}\n",
        "  mrr_total=[]\n",
        "  #thematic_matrix=calc_order(adjacency_matrix)\n",
        "  #iterate over the ids of the test_node variable df\n",
        "  for id in test_nodes['id']:\n",
        "\n",
        "    #article index adjusted for adjacency matrix index\n",
        "    article_idx=node_names[node_names[\"titre\"]==id].index-1\n",
        "    #find the values that are non zero in the vector\n",
        "    pertinent_articles_index=adjacency_matrix[article_idx].nonzero()[1]\n",
        "\n",
        "    #create a dictionary of the frequency of recommendation for each article\n",
        "    dict_similar[id]={}\n",
        "    mrr_test=[]\n",
        "    print('**',test_nodes.loc[test_nodes['id']==id,'titre'].iloc[0],'**')\n",
        "    #iterate over the pertinent article index which are non zero\n",
        "    for a in pertinent_articles_index:\n",
        "      #copy the adjacency matrix\n",
        "      M_ad=adjacency_matrix.copy()\n",
        "      #leave one out by equalling the coordinate to zero\n",
        "      M_ad[article_idx,a]=0\n",
        "      #perform the thematic calculation of the vector (similar to #2)\n",
        "      if Thematic:\n",
        "        them_vector=calc_order(M_ad,article_idx)\n",
        "        #find the cosine similarity for the result of the thematic vector\n",
        "        sim=np.array([cosine_similarity(them_vector, M_ad)[0]])\n",
        "        \n",
        "      else:\n",
        "        #perform the cosine similarity over the regular adjacency matrix\n",
        "        sim=np.array([cosine_similarity(M_ad[article_idx], M_ad)[0]])\n",
        "        \n",
        "      sim[sim>0]=1\n",
        "      sim[0,article_idx]=0\n",
        "      \n",
        "      r=calcul_thematique_rank2(M_ad,sim)\n",
        "      rang_nulle=sum(list(range(np.count_nonzero(sim),len(sim))))/(len(sim)-np.count_nonzero(sim))\n",
        "\n",
        "      #put cosine similarity of the article with itself to 0\n",
        "      #sim[article_idx]=0\n",
        "      #calculate pagerank\n",
        "      r_index_sorted=np.argsort(r.T[0])[::-1]\n",
        "\n",
        "      #sort and find the length of the non zero variable to keep them\n",
        "      similar_article=np.argsort(sim)[::-1][:len(sim[sim>0])][0]\n",
        "      #initialize an empty mrr array\n",
        "      mrr_list=[]\n",
        "      if a in similar_article:\n",
        "        #print(\"Yes\")\n",
        "        rank_relevant_article=np.where(r_index_sorted==a)[0][0]+1\n",
        "        #appending mrr of each artcle to the list\n",
        "        mrr_list.append(1/rank_relevant_article)\n",
        "      else:\n",
        "        #print(\"NO\")\n",
        "        mrr_list.append(1/rang_nulle)\n",
        "      \n",
        "      for b in pertinent_articles_index:\n",
        "        if b!=a:\n",
        "          rang_rest=np.where(r_index_sorted==b)[0][0]+1\n",
        "          mrr_list.append(1/rang_rest)\n",
        "      mrr_test.append(statistics.mean(mrr_list))\n",
        "    print(\"For which the MRR is :\")\n",
        "    print(statistics.mean(mrr_test))\n",
        "    mrr_total.append(statistics.mean(mrr_test))\n",
        "  \n",
        "  meant_total=statistics.mean(mrr_total)\n",
        "  print(f'\\n ***Mean MRR for 12 test article is:*** {meant_total}')\n",
        "  \n",
        "  #we can also print the top recommended articles based on similarity if necessary \n",
        "      \n",
        "  # print(dict_similar)\n",
        "  # for id in dict_similar.keys():\n",
        "  #   mrr_list=[]\n",
        "  #   print(id)\n",
        "  #   print(\"using Leave one out cross validation:\")\n",
        "  #   print the articles as recommendation system that have been recommended more than others during Leave-One-Out\n",
        "  #   recom_list=list(sorted(dict_similar[id], key=dict_similar[id].get, reverse=True))[:10] \n",
        "  #   print(recom_list)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "QDKqhXsbpQqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_recom_similarity(adjacency_matrix,node_names,test_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue3xGe3S5ygB",
        "outputId": "e10209b9-8838-4849-9427-82d03068d7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Joint Energy Management and Resource Allocation in Rechargeable Sensor Networks **\n",
            "For which the MRR is :\n",
            "0.17215400196174838\n",
            "** Qualitative organization of collections of shapes via quartet analysis **\n",
            "For which the MRR is :\n",
            "0.11558261988955752\n",
            "** Using the fuzzy multi-criteria decision making approach for measuring the possibility of successful knowledge management **\n",
            "For which the MRR is :\n",
            "0.07766800803288629\n",
            "** Multi-Scale Adaptive Sampling with Mobile Agents for Mapping of Forest Fires **\n",
            "For which the MRR is :\n",
            "0.4418463441500984\n",
            "** Randomized locality sensitive vocabularies for bag-of-features model **\n",
            "For which the MRR is :\n",
            "0.08839229795927607\n",
            "** Cache-Leakage Resilient OS Isolation in an Idealized Model of Virtualization **\n",
            "For which the MRR is :\n",
            "0.05891633562552609\n",
            "** Discrete tracking of parametrized curves **\n",
            "For which the MRR is :\n",
            "0.16089212248452056\n",
            "** Spatial template extraction for image retrieval by region matching. **\n",
            "For which the MRR is :\n",
            "0.1453262127223392\n",
            "** Distance sets for shape filters and shape recognition. **\n",
            "For which the MRR is :\n",
            "0.05431032044870626\n",
            "** Automating cross-layer diagnosis of enterprise wireless networks **\n",
            "For which the MRR is :\n",
            "0.1217525023078073\n",
            "** Content delivery and caching from a network provider's perspective **\n",
            "For which the MRR is :\n",
            "0.08553963177119031\n",
            "** A review of recent advances in learner and skill modeling in intelligent learning environments **\n",
            "For which the MRR is :\n",
            "0.0239662772139879\n",
            "\n",
            " ***Mean MRR for 12 test article is:*** 0.12886222288063703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_recom_similarity(adjacency_matrix,node_names,test_nodes,Thematic=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D9NwjWB6Ez1",
        "outputId": "45760149-3308-4cf1-aef2-49ac6597656b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Joint Energy Management and Resource Allocation in Rechargeable Sensor Networks **\n",
            "For which the MRR is :\n",
            "0.001501486834851921\n",
            "** Qualitative organization of collections of shapes via quartet analysis **\n",
            "For which the MRR is :\n",
            "0.0006459870156159253\n",
            "** Using the fuzzy multi-criteria decision making approach for measuring the possibility of successful knowledge management **\n",
            "For which the MRR is :\n",
            "0.0013891903462509435\n",
            "** Multi-Scale Adaptive Sampling with Mobile Agents for Mapping of Forest Fires **\n",
            "For which the MRR is :\n",
            "0.0005702031457593413\n",
            "** Randomized locality sensitive vocabularies for bag-of-features model **\n",
            "For which the MRR is :\n",
            "0.01690266448343102\n",
            "** Cache-Leakage Resilient OS Isolation in an Idealized Model of Virtualization **\n",
            "For which the MRR is :\n",
            "0.0020666930319984925\n",
            "** Discrete tracking of parametrized curves **\n",
            "For which the MRR is :\n",
            "0.0075574706503116346\n",
            "** Spatial template extraction for image retrieval by region matching. **\n",
            "For which the MRR is :\n",
            "0.002313008770684122\n",
            "** Distance sets for shape filters and shape recognition. **\n",
            "For which the MRR is :\n",
            "0.001858625120994004\n",
            "** Automating cross-layer diagnosis of enterprise wireless networks **\n",
            "For which the MRR is :\n",
            "0.0011818451612220242\n",
            "** Content delivery and caching from a network provider's perspective **\n",
            "For which the MRR is :\n",
            "0.0014132474548939915\n",
            "** A review of recent advances in learner and skill modeling in intelligent learning environments **\n",
            "For which the MRR is :\n",
            "0.00017473048782762566\n",
            "\n",
            " ***Mean MRR for 12 test article is:*** 0.0031312627086534203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analysis  \n",
        "In Q3 first we calculate similarity of each test article with other articles in the adjacency matrix. We used two methods to consider test article as vector space: 1- references of the article, 2- Thematic graph like Q2. As the result shows considering references gives better MRR because in this case the teleportation set is small and therefore the probability of teleportation increases and since the references is more probably in the similar articles, we have higher rank for them.  \n",
        "  \n",
        "\n",
        "But in the case of similarity for thematic matrix the set is big, and it is quite close to adjacency matrix, so the teleportation probability is quite close to random walk in general pagerank ((1-d)/N).  \n",
        "  \n",
        "\n",
        "In conclusion we can say as we move toward more topic specific (personalized) set in teleportation and limit teleportation set to the articles that we want we will get better MRR. \n"
      ],
      "metadata": {
        "id": "sOTU56aVx3GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4"
      ],
      "metadata": {
        "id": "pdeNDFAGqD68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ranking the personalized pageranks with the similarity method\n",
        "def calcul_rank_personalise(adjacency_matrix,thematic_matrix,article_idx, d=0.85,  max_iter=1000, epsilon=1e-5):\n",
        "  #initialize page rank\n",
        "\n",
        "  #initialize this time the initial pagerank to 1s\n",
        "  r_prev=np.array([[1]]*adjacency_matrix.shape[0])\n",
        "\n",
        "  \n",
        "  #create the undirected graph\n",
        "  non_directed_mat=adjacency_matrix.T+adjacency_matrix\n",
        "  non_directed_mat[non_directed_mat>1]=1\n",
        "  #calculate the similarity between the thematic and undirected graph\n",
        "  sim=np.array(cosine_similarity(thematic_matrix, non_directed_mat))\n",
        "\n",
        "  #putting our article index from the similarity to 0\n",
        "  sim[0,article_idx]=0\n",
        "\n",
        "  #we performed a hyper-parameter research for this part that will be explained in the analysis\n",
        "  # this variable contains the best 99.9% of the similarities indexes for the given thematic_matrix\n",
        "  similar_articles_index=np.where(sim>np.quantile(sim,0.999))[1]\n",
        "\n",
        "  #the teleportation matrix is the one that will let the random jump to be focused towards articles with higher similarity\n",
        "\n",
        "  #fix the teleportation matrix to the similarity+threshold\n",
        "  teleport=np.array([[0]]*adjacency_matrix.shape[0])\n",
        "  teleport[similar_articles_index]=1\n",
        "\n",
        "  #iterate until convergence of the previous-current pagerank\n",
        "  for i in range(max_iter):\n",
        "    #calculating the current pagerank\n",
        "    r_cur=np.array(((1-d)/len(teleport[teleport==1])*teleport)+d*(adjacency_matrix.T*(r_prev/(adjacency_matrix.sum(axis=1)+1)))) #(m_l_o.T*(r_prev/(m_l_o.sum(axis=1)+1))))\n",
        "    if np.mean(np.abs(r_cur-r_prev))<1e-5:\n",
        "      #to know the number of iteration to achive convergence we print i\n",
        "      #print(f'number of iteration was: {i}')\n",
        "      break\n",
        "    else:\n",
        "      #convergence process\n",
        "      r_prev=r_cur\n",
        "\n",
        "  return r_cur\n",
        "\n"
      ],
      "metadata": {
        "id": "7lOJx74DAHQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main function\n",
        "def PPR(test_nodes,adjacency_matrix):    \n",
        "    results=[]\n",
        "    #iterate over the ids of test_nodes\n",
        "    for id in test_nodes['id']:#3000 (,3262,3276)\n",
        "        #keep the index of the id\n",
        "        ind=node_names[node_names[\"titre\"]==id].index[0]-1\n",
        "        print('**',test_nodes.loc[test_nodes['id']==id,'titre'].iloc[0],'**')\n",
        "\n",
        "        #find the row for the given id on the original adjacency matrix\n",
        "        articles_ref=adjacency_matrix[node_names[node_names[\"titre\"]==id].index-1]\n",
        "        # finding it on the thematic matrix\n",
        "        article_them=calc_order(adjacency_matrix,ind)\n",
        "\n",
        "        #keeping the original line for the id\n",
        "        articles_sparse_original_ref=articles_ref.toarray()[0]\n",
        "        #and the thematic one also\n",
        "        articles_sparse_original_them=article_them.toarray()[0]\n",
        "\n",
        "        rank_lov=[]\n",
        "        #iterate over the non zero values of the original line/vector\n",
        "        for a in list(np.nonzero(articles_sparse_original_ref)[0]):\n",
        "          \n",
        "            #leave-one out method by turning the a value to 0 on the adjacency matrix\n",
        "            article_sparse=articles_sparse_original_ref.copy()\n",
        "            article_sparse[a]=0\n",
        "            adjacency_thematique=adjacency_matrix.copy()\n",
        "            adjacency_thematique[ind,a]=0\n",
        "\n",
        "            #calculating the thematic vector for the index of ind from the new adjacency matrix\n",
        "            #thematique=calc_order(adjacency_thematique,ind)\n",
        "            thematique=adjacency_thematique[ind]\n",
        "\n",
        "\n",
        "            #ranking through the personnalized pagerank\n",
        "            rang_sort=calcul_rank_personalise(adjacency_matrix,thematique,ind)\n",
        "            #sorting\n",
        "            rang_sort=np.argsort(rang_sort.T[0])[::-1]\n",
        "            mrr_list=[]\n",
        "\n",
        "            #calculating the mrr for the non zero values of the vector\n",
        "            for b in list(np.nonzero(articles_sparse_original_ref)[0]):\n",
        "\n",
        "              rang=np.where(rang_sort==b)[0][0]+1\n",
        "              mrr_list.append(1/rang)\n",
        "            rank_lov.append(statistics.mean(mrr_list))\n",
        "        print(\"For which the MRR is :\")\n",
        "        results.append(statistics.mean(rank_lov))\n",
        "        print(statistics.mean(rank_lov))\n",
        "    print(f'\\n ***Mean MRR for 12 test article is:*** {statistics.mean(results)}')\n",
        "\n",
        "\n",
        "PPR(test_nodes,adjacency_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc5uUNQ0_Drj",
        "outputId": "0daa5798-e082-4d5b-b5f2-cc0c5bc10155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Joint Energy Management and Resource Allocation in Rechargeable Sensor Networks **\n",
            "For which the MRR is :\n",
            "0.18998268520905115\n",
            "** Qualitative organization of collections of shapes via quartet analysis **\n",
            "For which the MRR is :\n",
            "0.12961742202601714\n",
            "** Using the fuzzy multi-criteria decision making approach for measuring the possibility of successful knowledge management **\n",
            "For which the MRR is :\n",
            "0.0435160126299041\n",
            "** Multi-Scale Adaptive Sampling with Mobile Agents for Mapping of Forest Fires **\n",
            "For which the MRR is :\n",
            "0.4069865996308824\n",
            "** Randomized locality sensitive vocabularies for bag-of-features model **\n",
            "For which the MRR is :\n",
            "0.1613555341245791\n",
            "** Cache-Leakage Resilient OS Isolation in an Idealized Model of Virtualization **\n",
            "For which the MRR is :\n",
            "0.06609447524725721\n",
            "** Discrete tracking of parametrized curves **\n",
            "For which the MRR is :\n",
            "0.1476563645228442\n",
            "** Spatial template extraction for image retrieval by region matching. **\n",
            "For which the MRR is :\n",
            "0.1525527776817748\n",
            "** Distance sets for shape filters and shape recognition. **\n",
            "For which the MRR is :\n",
            "0.048616934550813125\n",
            "** Automating cross-layer diagnosis of enterprise wireless networks **\n",
            "For which the MRR is :\n",
            "0.20347369070616836\n",
            "** Content delivery and caching from a network provider's perspective **\n",
            "For which the MRR is :\n",
            "0.14544272638676753\n",
            "** A review of recent advances in learner and skill modeling in intelligent learning environments **\n",
            "For which the MRR is :\n",
            "0.045121957260885186\n",
            "\n",
            " ***Mean MRR for 12 test article is:*** 0.14503476499807869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "We have proceeded to do a mixture of question 2 and question 3 to obtain a personnalized pagerank. Here, the difference from question 2 is the usage of the cosine similarity for every article in the test node between the articles index obtained because of the thematic modification of the article vector from the chain levels of relations. Another difference to question 2 is that we used the original content matrix contains all the articles because it was the one that provided the better results compared to the thematic matrix in Q3.\n",
        "\n",
        "The difference from Question 3 is that we applied the similarity to the adjacency matrix for an undirected graph (relation 1 and relation -1 together) and we only took the best 99.9% similarities for the teleportation vector. This is basically a hyper-parameter that we decided to find by doing at first a greedy search, we tried different scalar values between 0.01 and 0.1. Following the error message that left us with the null vector for the teleportation matrix, we decided to try out the quantile method from the NumPy library. At first there was almost little to no improvement from our question 3 results for the quantiles ranging from 0 to 0.8. But soon after we also found out that if we demanded too little non null components in the teleportation vector, we would end with a very low MRR (try a quantile of 0.9999, for which mrr was 0.05). The ***optimal hyperparameter*** for us was therefore the 0.999 quantile for the teleportation matrix for every single non null article in the adjacency vector given a test node. This article-by-article similarity cutting points (quantile) is the part makes our method very personalized. \n",
        "\n",
        "In fact this is also reflected by a better resulf of mrr than any method we have tried before : 0.14503476499807869.\n",
        "\n",
        "There are other methods that could be better in terms of personnalization  (like using the Citation Network Dataset V13 in its entirety but we would have calculated a similary through the 'keyword' or a tokenized 'indexed_abstract' variable. But these methods would have cost us much more RAM and CPU usage. And unfortunately we are not equipped for these much complexe on such dense graphs. We may have a very decent and optimal-complexity method for the personnalized pagerank considering our limited ressources. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uVlbArNwG-C4"
      }
    }
  ]
}